{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8c0c9fe97d364228947874d8c0496e34":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72e7450d199846caae19acef945ae2c0","IPY_MODEL_4bd22415a0c544deabab4cda8248dedd","IPY_MODEL_19c67bba722e4ba69385ac307cfa3add"],"layout":"IPY_MODEL_0f2af29434544c178132d6cf204677cf"}},"72e7450d199846caae19acef945ae2c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f09b225927f84ef0948caae2098229a8","placeholder":"​","style":"IPY_MODEL_39cc0794f91e4bf08e92c42584272bdf","value":"config.json: 100%"}},"4bd22415a0c544deabab4cda8248dedd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ec5503ff20348f6a41e50715491ecae","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_69fe3bce5f8f414995964e8f82bb229e","value":483}},"19c67bba722e4ba69385ac307cfa3add":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc969f2250e3441990fa323741c1b7ce","placeholder":"​","style":"IPY_MODEL_3ec5534183a9454b89ca03423e26d991","value":" 483/483 [00:00&lt;00:00, 7.80kB/s]"}},"0f2af29434544c178132d6cf204677cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f09b225927f84ef0948caae2098229a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39cc0794f91e4bf08e92c42584272bdf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ec5503ff20348f6a41e50715491ecae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69fe3bce5f8f414995964e8f82bb229e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc969f2250e3441990fa323741c1b7ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ec5534183a9454b89ca03423e26d991":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22e7b3a31dca404ca68e40b8af1e55fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd00fcd89e3648b887de4a6f9643ad1a","IPY_MODEL_e092307def17414a9e2c9d7bfe17cf0c","IPY_MODEL_d6dfc4d7f087460ea9a93271c4b7c51c"],"layout":"IPY_MODEL_05284b3426204bc58b39c2d5dcaa5839"}},"fd00fcd89e3648b887de4a6f9643ad1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd1b674698994549b52448462a2e0224","placeholder":"​","style":"IPY_MODEL_91c10e0e0aad432f84ad5e64596e7221","value":"model.safetensors: 100%"}},"e092307def17414a9e2c9d7bfe17cf0c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5962cbfb520d4d0c826375f12a106df7","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_db30f0f65681489aa5eb9157d61d0518","value":267954768}},"d6dfc4d7f087460ea9a93271c4b7c51c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81e691a39aae49058e1999677b6b187e","placeholder":"​","style":"IPY_MODEL_8628ffb979e547afb2d032b552b5ac5d","value":" 268M/268M [00:04&lt;00:00, 54.4MB/s]"}},"05284b3426204bc58b39c2d5dcaa5839":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd1b674698994549b52448462a2e0224":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91c10e0e0aad432f84ad5e64596e7221":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5962cbfb520d4d0c826375f12a106df7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db30f0f65681489aa5eb9157d61d0518":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"81e691a39aae49058e1999677b6b187e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8628ffb979e547afb2d032b552b5ac5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## 환경 설정"],"metadata":{"id":"CatmkL5wDus_"}},{"cell_type":"code","source":["!pip install mxnet\n","!pip install gluonnlp==0.8.0\n","!pip install tqdm pandas\n","!pip install sentencepiece\n","!pip install transformers\n","!pip install torch>=1.8.1\n","\n","!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DkAShrKQ8QwC","outputId":"3750610f-1dc6-4c09-a33c-3222da852391","executionInfo":{"status":"ok","timestamp":1700328205313,"user_tz":-540,"elapsed":58080,"user":{"displayName":"김기훈","userId":"11939944553988434311"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mxnet\n","  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (1.23.5)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (2.31.0)\n","Collecting graphviz<0.9.0,>=0.8.1 (from mxnet)\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2023.7.22)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.20.1\n","    Uninstalling graphviz-0.20.1:\n","      Successfully uninstalled graphviz-0.20.1\n","Successfully installed graphviz-0.8.4 mxnet-1.9.1\n","Collecting gluonnlp==0.8.0\n","  Downloading gluonnlp-0.8.0.tar.gz (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gluonnlp==0.8.0) (1.23.5)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.8.0-py3-none-any.whl size=292695 sha256=7892864b6298267b3e9077c4eb1d123868a99814422fbd35102981879df4ed8f\n","  Stored in directory: /root/.cache/pip/wheels/2d/cc/dc/7ec84dced25f738b8be400101abb67e4b50c905090a51017e4\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.8.0\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Collecting kobert_tokenizer\n","  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-5wv4_pjv/kobert-tokenizer_6ca4253ef58a48c3bb51bbf53e0b454d\n","  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-5wv4_pjv/kobert-tokenizer_6ca4253ef58a48c3bb51bbf53e0b454d\n","  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: kobert_tokenizer\n","  Building wheel for kobert_tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert_tokenizer: filename=kobert_tokenizer-0.1-py3-none-any.whl size=4632 sha256=4f9d8c526945654eb62f9a4ef9adb9e615ea9d3871b640a3f058dc62cb70c07c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-lw1f5v5h/wheels/e9/1a/3f/a864970e8a169c176befa3c4a1e07aa612f69195907a4045fe\n","Successfully built kobert_tokenizer\n","Installing collected packages: kobert_tokenizer\n","Successfully installed kobert_tokenizer-0.1\n"]}]},{"cell_type":"code","source":["!pip install mecab-python3\n","!pip install konlpy\n","!pip install tensorflow-text\n","!pip install soynlp\n","!pip install -v python-mecab-ko\n","!pip install sentencepiece"],"metadata":{"id":"r5pB917s8JsX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bf5e65ed-be02-475a-fc5d-e143ae00bf26","executionInfo":{"status":"ok","timestamp":1700328311423,"user_tz":-540,"elapsed":106117,"user":{"displayName":"김기훈","userId":"11939944553988434311"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mecab-python3\n","  Downloading mecab_python3-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (581 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.7/581.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: mecab-python3\n","Successfully installed mecab-python3-1.0.8\n","Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n","  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n","Installing collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.4.1 konlpy-0.6.0\n","Collecting tensorflow-text\n","  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (0.15.0)\n","Collecting tensorflow<2.16,>=2.15.0 (from tensorflow-text)\n","  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (0.34.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.59.2)\n","Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16,>=2.15.0->tensorflow-text)\n","  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16,>=2.15.0->tensorflow-text)\n","  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras<2.16,>=2.15.0 (from tensorflow<2.16,>=2.15.0->tensorflow-text)\n","  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text) (0.41.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.5.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.2.2)\n","Installing collected packages: tensorflow-estimator, keras, tensorboard, tensorflow, tensorflow-text\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.14.0\n","    Uninstalling tensorflow-estimator-2.14.0:\n","      Successfully uninstalled tensorflow-estimator-2.14.0\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.14.0\n","    Uninstalling keras-2.14.0:\n","      Successfully uninstalled keras-2.14.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.14.1\n","    Uninstalling tensorboard-2.14.1:\n","      Successfully uninstalled tensorboard-2.14.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.14.0\n","    Uninstalling tensorflow-2.14.0:\n","      Successfully uninstalled tensorflow-2.14.0\n","Successfully installed keras-2.15.0 tensorboard-2.15.1 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-text-2.15.0\n","Collecting soynlp\n","  Downloading soynlp-0.0.493-py3-none-any.whl (416 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.8/416.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.10/dist-packages (from soynlp) (1.23.5)\n","Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.10/dist-packages (from soynlp) (5.9.5)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from soynlp) (1.11.3)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from soynlp) (1.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->soynlp) (3.2.0)\n","Installing collected packages: soynlp\n","Successfully installed soynlp-0.0.493\n","Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n","Collecting python-mecab-ko\n","  Downloading python_mecab_ko-1.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (573 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m573.9/573.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-mecab-ko-dic (from python-mecab-ko)\n","  Downloading python_mecab_ko_dic-2.1.1.post2-py3-none-any.whl (34.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: python-mecab-ko-dic, python-mecab-ko\n","Successfully installed python-mecab-ko-1.3.3 python-mecab-ko-dic-2.1.1.post2\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVxx7Ram9EVA","outputId":"dd8c9468-8033-4cb6-dc1e-983cef4367b5","executionInfo":{"status":"ok","timestamp":1700328336332,"user_tz":-540,"elapsed":24933,"user":{"displayName":"김기훈","userId":"11939944553988434311"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R42whrqo8V6R"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import json\n","import os\n","import re\n","from konlpy.tag import Kkma\n","from soynlp.normalizer import *\n","from soynlp.tokenizer import LTokenizer\n","from konlpy.tag import Komoran\n","from transformers import BertTokenizer\n","import mecab\n","import sentencepiece as spm"]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","from tqdm.notebook import tqdm"],"metadata":{"id":"OGdgszhM89tI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5811f82a-3011-4178-956e-a6d07f99ba7d","executionInfo":{"status":"ok","timestamp":1700328350662,"user_tz":-540,"elapsed":4928,"user":{"displayName":"김기훈","userId":"11939944553988434311"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/mxnet/optimizer/optimizer.py:163: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n","  warnings.warn('WARNING: New optimizer %s.%s is overriding '\n"]}]},{"cell_type":"code","source":["# Torch GPU 설정\n","device_type = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device = torch.device(device_type)"],"metadata":{"id":"k5O7Ftb18TLN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 데이터"],"metadata":{"id":"BSZqJL-zCHGe"}},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/WCRC/final_train_df.csv')\n","val_df = pd.read_csv('/content/drive/MyDrive/WCRC/final_val_df.csv')"],"metadata":{"id":"lkGHbdG4CIpw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/WCRC/018.감성대화/Training_221115_add/라벨링데이터/감성대화말뭉치(최종데이터)_Training/감성대화말뭉치(최종데이터)_Training.json', encoding=\"utf-8\") as f:\n","    labeled_data = json.load(f)\n","with open('/content/drive/MyDrive/WCRC/018.감성대화/Validation_221115_add/라벨링데이터/감성대화말뭉치(최종데이터)_Validation.json', encoding=\"utf-8\") as f:\n","    validation_data = json.load(f)"],"metadata":{"id":"z0SABvdrlPDb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 상황 분류 모델 예측"],"metadata":{"id":"H_E30NurD7jk"}},{"cell_type":"code","source":["# BERTSentenceTransform 수정\n","class BERTSentenceTransform:\n","    \"\"\"\n","    BERT 스타일의 데이터 변환 클래스.\n","\n","    Parameters\n","    ----------\n","    tokenizer : BERTTokenizer\n","        문장을 토큰화하는 토크나이저.\n","    max_seq_length : int\n","        문장의 최대 시퀀스 길이.\n","    vocab : BERTVocab\n","        토큰 변환을 위한 어휘.\n","    pad : bool, default True\n","        문장을 최대 길이로 패딩할지 여부.\n","    pair : bool, default True\n","        문장 또는 문장 쌍을 변환할지 여부.\n","    \"\"\"\n","\n","    def __init__(self, tokenizer, max_seq_length,vocab, pad=True, pair=True):\n","        self._tokenizer = tokenizer\n","        self._max_seq_length = max_seq_length\n","        self._pad = pad\n","        self._pair = pair\n","        self._vocab = vocab\n","\n","    def __call__(self, line):\n","        \"\"\"\n","        문장 쌍 또는 단일 문장에 대한 변환 수행.\n","\n","        Parameters\n","        ----------\n","        line: tuple of str\n","            입력 문자열. 문장 쌍의 경우 입력은 2개의 문자열로 이루어진 튜플이며:\n","            (text_a, text_b). 단일 문장의 경우 입력은 단일 문자열로 이루어진 튜플:\n","            (text_a,).\n","\n","        Returns\n","        -------\n","        np.array: 'int32' 형식의 입력 토큰 ID, 형태 (batch_size, seq_length)\n","        np.array: 'int32' 형식의 유효 길이, 형태 (batch_size,)\n","        np.array: 'int32' 형식의 입력 토큰 타입 ID, 형태 (batch_size, seq_length)\n","        \"\"\"\n","\n","        # 유니코드로 변환\n","        text_a = line[0]\n","        if self._pair:\n","            assert len(line) == 2\n","            text_b = line[1]\n","\n","        tokens_a = self._tokenizer.tokenize(text_a)\n","        tokens_b = None\n","\n","        if self._pair:\n","            tokens_b = self._tokenizer(text_b)\n","\n","        if tokens_b:\n","            # 'tokens_a' 및 'tokens_b'를 수정하여 총 길이가 지정된 길이보다 작아지도록 함\n","            # [CLS], [SEP], [SEP]에 해당하는 \"- 3\" 고려\n","            self._truncate_seq_pair(tokens_a, tokens_b,\n","                                    self._max_seq_length - 3)\n","        else:\n","            # [CLS] 및 [SEP]에 해당하는 \"- 2\" 고려\n","            if len(tokens_a) > self._max_seq_length - 2:\n","                tokens_a = tokens_a[0:(self._max_seq_length - 2)]\n","\n","        vocab = self._vocab\n","        tokens = []\n","        tokens.append(vocab.cls_token)\n","        tokens.extend(tokens_a)\n","        tokens.append(vocab.sep_token)\n","        segment_ids = [0] * len(tokens)\n","\n","        if tokens_b:\n","            tokens.extend(tokens_b)\n","            tokens.append(vocab.sep_token)\n","            segment_ids.extend([1] * (len(tokens) - len(segment_ids)))\n","\n","        input_ids = self._tokenizer.convert_tokens_to_ids(tokens)\n","\n","        # 문장의 길이\n","        valid_length = len(input_ids)\n","\n","        if self._pad:\n","            # 시퀀스 길이까지 제로 패딩\n","            padding_length = self._max_seq_length - valid_length\n","            # 나머지는 패딩 토큰으로 채움\n","            input_ids.extend([vocab[vocab.padding_token]] * padding_length)\n","            segment_ids.extend([0] * padding_length)\n","\n","        return np.array(input_ids, dtype='int32'), np.array(valid_length, dtype='int32'),\\\n","            np.array(segment_ids, dtype='int32')"],"metadata":{"id":"_ga7WDrI7yCR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from kobert_tokenizer import KoBERTTokenizer\n","from transformers import BertModel\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup\n","\n","class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len,\n","                 pad, pair):\n","        transform = BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len,vocab=vocab, pad=pad, pair=pair)\n","        #transform = nlp.data.BERTSentenceTransform(\n","        #    tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))"],"metadata":{"id":"yYO6oii0A1op"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 하이퍼 파라미터 설정\n","max_len = 64\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 50\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5"],"metadata":{"id":"v8Hh64ayBdVi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from kobert_tokenizer import KoBERTTokenizer\n","tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qn1M-ncXA6za","outputId":"8db2ac21-99c4-44db-ce58-43c45a86792d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'KoBERTTokenizer'.\n"]}]},{"cell_type":"code","source":["# kobert 공식 git에 있는 get_kobert_model 선언\n","def get_kobert_model(model_path, vocab_file, ctx=\"cpu\"):\n","    bertmodel = BertModel.from_pretrained(model_path)\n","    device = torch.device(ctx)\n","    bertmodel.to(device)\n","    bertmodel.eval()\n","    vocab_b_obj = nlp.vocab.BERTVocab.from_sentencepiece(vocab_file,\n","                                                         padding_token='[PAD]')\n","    return bertmodel, vocab_b_obj"],"metadata":{"id":"H6kGgKXjA1re"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gluonnlp as nlp\n","from transformers import BertModel\n","bertmodel, vocab = get_kobert_model('skt/kobert-base-v1',tokenizer.vocab_file)\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower = False)"],"metadata":{"id":"eSDunArGA1tz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes = 12,   # 상황 클래스 수로 조정 클래스 12개\n","                 dr_rate = None,\n","                 params = None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","\n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p = dr_rate)\n","\n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","\n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device),return_dict = False)\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)"],"metadata":{"id":"VmrheCcMA1zn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 저장한 모델 불러오기\n","loaded_model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)\n","checkpoint_path = '/content/drive/MyDrive/WCRC/situation_model.pth'  # 모델 체크포인트 파일 경로\n","loaded_model.load_state_dict(torch.load(checkpoint_path))\n","loaded_model.eval()\n","\n","# 예측할 문장\n","input_sentence = \"직장 동료와 상사들이랑 친하게 지내야겠어.\"\n","\n","# 입력 문장을 BERT 모델의 입력 형식으로 변환\n","transform = BERTSentenceTransform(tokenizer, max_seq_length=max_len, vocab=vocab, pad=True, pair=False)\n","input_data = transform([input_sentence])\n","\n","# 토큰 ID, 유효 길이, 토큰 타입 ID를 추출\n","input_token_ids, input_valid_length, input_segment_ids = input_data\n","\n","# 텐서로 변환\n","input_token_ids = torch.tensor([input_token_ids], dtype=torch.long).to(device)\n","input_valid_length = torch.tensor(input_valid_length, dtype=torch.long).to(device)  # 스칼라 값으로 전달\n","input_segment_ids = torch.tensor([input_segment_ids], dtype=torch.long).to(device)\n","\n","# 예측 수행\n","with torch.no_grad():\n","    input_valid_length = torch.tensor([input_valid_length], dtype=torch.long).to(device)  # 스칼라 값으로 전달\n","    output = loaded_model(input_token_ids, input_valid_length, input_segment_ids)\n","    predicted_situation_label = torch.argmax(output, dim=1).item()\n","\n","print(\"Predicted Label:\", predicted_situation_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oY6WRLf3BHEb","outputId":"278ab828-bde4-44cc-fc9c-4b5394fbe8de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Label: 1\n"]}]},{"cell_type":"markdown","source":["## 감정 분류 모델 예측"],"metadata":{"id":"d5P3kpzpCVOm"}},{"cell_type":"code","source":["import torch.nn as nn\n","from transformers import DistilBertModel\n","\n","class JointDistilBertModel(nn.Module):\n","    def __init__(self, num_intents, dropout_rate=0.4):\n","        super(JointDistilBertModel, self).__init__()\n","        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.intent_classifier = nn.Linear(self.distilbert.config.dim, num_intents)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled_output = outputs.last_hidden_state[:, 0]  # First token of the last hidden state\n","        pooled_output = self.dropout(pooled_output)\n","        intent_logits = self.intent_classifier(pooled_output)\n","        return intent_logits\n","num_intents = 6\n","\n","model = JointDistilBertModel(6)\n","model.load_state_dict(torch.load('/content/drive/MyDrive/WCRC/emotion_model.pth'))\n","model.eval()"],"metadata":{"id":"ENurHbChecWy","colab":{"base_uri":"https://localhost:8080/","height":680,"referenced_widgets":["8c0c9fe97d364228947874d8c0496e34","72e7450d199846caae19acef945ae2c0","4bd22415a0c544deabab4cda8248dedd","19c67bba722e4ba69385ac307cfa3add","0f2af29434544c178132d6cf204677cf","f09b225927f84ef0948caae2098229a8","39cc0794f91e4bf08e92c42584272bdf","4ec5503ff20348f6a41e50715491ecae","69fe3bce5f8f414995964e8f82bb229e","bc969f2250e3441990fa323741c1b7ce","3ec5534183a9454b89ca03423e26d991","22e7b3a31dca404ca68e40b8af1e55fd","fd00fcd89e3648b887de4a6f9643ad1a","e092307def17414a9e2c9d7bfe17cf0c","d6dfc4d7f087460ea9a93271c4b7c51c","05284b3426204bc58b39c2d5dcaa5839","cd1b674698994549b52448462a2e0224","91c10e0e0aad432f84ad5e64596e7221","5962cbfb520d4d0c826375f12a106df7","db30f0f65681489aa5eb9157d61d0518","81e691a39aae49058e1999677b6b187e","8628ffb979e547afb2d032b552b5ac5d"]},"executionInfo":{"status":"ok","timestamp":1700331429707,"user_tz":-540,"elapsed":8088,"user":{"displayName":"김기훈","userId":"11939944553988434311"}},"outputId":"5aa53d7a-7b45-4d75-a514-3e146b9ff8c6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c0c9fe97d364228947874d8c0496e34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22e7b3a31dca404ca68e40b8af1e55fd"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["JointDistilBertModel(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0-5): 6 x TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.4, inplace=False)\n","  (intent_classifier): Linear(in_features=768, out_features=6, bias=True)\n",")"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["def preprocess_input(text, tokenizer, max_length=512):\n","    # 입력 데이터 토큰화\n","    encoded_input = tokenizer.encode_plus(\n","        text,\n","        add_special_tokens=True,\n","        max_length=max_length,\n","        padding='max_length',\n","        return_attention_mask=True,\n","        truncation=True\n","    )\n","    input_ids = torch.tensor([encoded_input['input_ids']], dtype=torch.long)\n","    attention_mask = torch.tensor([encoded_input['attention_mask']], dtype=torch.long)\n","    return input_ids, attention_mask"],"metadata":{"id":"IHxmZ8wsozRf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def index_to_emotion(index):\n","    # 감정 매핑\n","    emotion_labels = {0: \"불안\", 1: \"분노\", 2: \"상처\", 3: \"슬픔\", 4: \"당황\", 5: \"기쁨\"}\n","    return emotion_labels.get(index, \"Unknown\")"],"metadata":{"id":"2SugMLC3oLGy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_emotion(text, model, tokenizer):\n","    input_ids, attention_mask = preprocess_input(text, tokenizer)\n","\n","    with torch.no_grad():\n","        outputs = model(input_ids, attention_mask)\n","        prediction = torch.argmax(outputs, dim=1)\n","\n","    # Convert the prediction to the corresponding emotion label\n","    # Assuming you have a function or a dictionary to map prediction indices to emotion labels\n","    # emotion_label = index_to_emotion(prediction.item())  # Define this mapping as per your dataset\n","    emotion_label = int(prediction.item())\n","\n","    return emotion_label"],"metadata":{"id":"h-tmcFPfn4V3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 예시 텍스트\n","example_text = '나 요즘 매일 퇴사를 고민 하고 있는데 너무 힘들다.'\n","\n","# 예측\n","predicted_emotion_label = predict_emotion(example_text, model, tokenizer)\n","print(f\"당신의 감정은: {predicted_emotion_label}\")"],"metadata":{"id":"wAj2-yL4pvBR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 답변 생성"],"metadata":{"id":"Y9q0iaYHeQr7"}},{"cell_type":"code","source":["from konlpy.tag import Okt\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import pandas as pd\n","\n","# '사람문장_명사' 열의 문장을 공백을 기준으로 단어로 나누어 리스트로 변환\n","train_df['사람문장_명사'] = train_df['사람문장_명사'].apply(lambda x: x.split() if isinstance(x, str) else [])\n","\n","# 명사 추출 함수 정의\n","def extract_nouns(sentence):\n","    okt = Okt()\n","    nouns = okt.nouns(sentence)\n","    return ' '.join(nouns)\n","\n","def get_most_similar_response(sentence, dataframe, situation_keyword, emotion_category):\n","    # 상황키워드와 감정대분류에 해당하는 행들만 필터링\n","    filtered_df = dataframe[(dataframe['상황키워드'] == situation_keyword) & (dataframe['감정_대분류'] == emotion_category)]\n","\n","    # 명사 추출\n","    input_nouns = extract_nouns(sentence)\n","\n","    # '사람문장_명사' 값을 가져와서 문장 벡터화\n","    vectorizer = CountVectorizer()\n","    # 리스트를 문자열로 변환하여 공백으로 구분된 단어들의 문자열로 만듦\n","    sentence_vector = vectorizer.fit_transform(filtered_df['사람문장_명사'].apply(lambda x: ' '.join(x)))\n","\n","    # 입력 문장을 벡터화\n","    input_vector = vectorizer.transform([input_nouns])\n","\n","    # 코사인 유사도 계산\n","    similarities = cosine_similarity(input_vector, sentence_vector).flatten()\n","\n","    if similarities.size == 0:\n","        return \"죄송합니다. 다시 입력해주세요.\"\n","\n","    # 가장 유사한 행의 인덱스 가져오기\n","    most_similar_index = similarities.argmax()\n","\n","    # 가장 유사한 답변 반환\n","    return filtered_df.iloc[most_similar_index]['시스템문장']\n","\n","# 예시 문장\n","input_sentence = \"남들은 결혼 전에 일억을 모았다는데 난 뭐를 한 것인지 모르겠어. 자괴감만 드네\"\n","\n","# 함수 호출\n","response = get_most_similar_response(input_sentence, train_df, predicted_situation_label, predicted_emotion_label)\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60_iVU6be5cZ","outputId":"6c6e393a-716c-4bd1-e0b7-d3aec50586a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["결혼 하면 어떤 점에서 그렇게 느끼게 만드나요?\n"]}]},{"cell_type":"code","source":["# 예시 문장\n","input_sentence = \"회사에서 중요한 프로젝트를 혼자 하게 됐는데 솔직히 두렵고 무서워.\"\n","\n","# 함수 호출\n","response = get_most_similar_response(input_sentence, train_df, predicted_situation_label, predicted_emotion_label)\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kXtsGzLce-FA","outputId":"29606ff4-7a79-4c49-ab2c-1619bc0b7c5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["큰 프로젝트를 혼자 하셔서 고민이 많겠네요.\n"]}]},{"cell_type":"code","source":["from konlpy.tag import Okt\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import pandas as pd\n","\n","# '사람문장_명사' 열의 문장을 공백을 기준으로 단어로 나누어 리스트로 변환\n","# train_df['사람문장_명사'] = train_df['사람문장_명사'].apply(lambda x: x.split() if isinstance(x, str) else [])\n","\n","# 명사 추출 함수 정의\n","def extract_nouns(sentence):\n","    okt = Okt()\n","    nouns = okt.nouns(sentence)\n","    return ' '.join(nouns)\n","\n","def get_most_similar_response(sentence, dataframe, situation_keyword, emotion_category):\n","    # 상황키워드와 감정대분류에 해당하는 행들만 필터링\n","    filtered_df = dataframe[(dataframe['상황키워드'] == situation_keyword) & (dataframe['감정_대분류'] == emotion_category)]\n","\n","    # 명사 추출\n","    input_nouns = extract_nouns(sentence)\n","\n","    # '사람문장_명사' 값을 가져와서 문장 벡터화\n","    vectorizer = CountVectorizer()\n","    # 리스트를 문자열로 변환하여 공백으로 구분된 단어들의 문자열로 만듦\n","    sentence_vector = vectorizer.fit_transform(filtered_df['사람문장_명사'].apply(lambda x: ' '.join(x)))\n","\n","    # 입력 문장을 벡터화\n","    input_vector = vectorizer.transform([input_nouns])\n","\n","    # 코사인 유사도 계산\n","    similarities = cosine_similarity(input_vector, sentence_vector).flatten()\n","\n","    if similarities.size == 0:\n","        return \"죄송합니다. 다시 입력해주세요.\"\n","\n","    # 가장 유사한 행의 인덱스 가져오기\n","    most_similar_index = similarities.argmax()\n","\n","    # 가장 유사한 답변 반환\n","    response = filtered_df.iloc[most_similar_index]['시스템문장']\n","    return response\n","\n","# 초기 대화 시작\n","print(\"안녕하세요! 상황과 감정에 관한 이야기를 나눠봐요.\")\n","print(\"종료하려면 '종료'를 입력하세요.\")\n","\n","while True:\n","    # 사용자 입력 받기\n","    user_input = input(\"사용자: \")\n","\n","    # 종료 조건 확인\n","    if user_input == '종료':\n","        print(\"대화를 종료합니다.\")\n","        break\n","\n","    # 이전에 예측된 상황과 감정에 대한 답변 가져오기\n","    response = get_most_similar_response(user_input, train_df, predicted_situation_label, predicted_emotion_label)\n","\n","    # 답변 출력\n","    print(\"챗봇:\", response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GFIwi6UsD9WW","outputId":"0fc54e78-9531-485d-a4de-f8b6817386b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요! 상황과 감정에 관한 이야기를 나눠봐요.\n","종료하려면 '종료'를 입력하세요.\n","사용자: 이번 프로젝트에서 발표를 하는데 내가 실수하는 바람에 우리 팀이 감점을 받았어. 너무 미안해.\n","챗봇: 실수하시다니 정말 죄송한 마음이 크겠어요.\n","사용자: 퇴근 후 여가에 회사 일을 더 열심히 해서 피해가 가지 않도록 해야겠어.\n","챗봇: 퇴근 후에도 일을 추가로 해서 만회하려고 하시는군요. 앞으로 어떤 점이 달라지기를 기대하시나요?\n","사용자: 내 능력이 부족한 거 같은데 그만 다녀야 될거같아.\n","챗봇: 능력을 올리려면 어떤 방법이 있을까요?\n","사용자: 회사에서 중요한 프로젝트를 혼자 하게 됐는데 솔직히 두렵고 무서워.\n","챗봇: 큰 프로젝트를 혼자 하셔서 고민이 많겠네요.\n","사용자: 나에게 너무 크게 느껴지는 중요한 프로젝트라 버거운 느낌이 들어.\n","챗봇: 프로젝트를 잘하시기 위해서 어떤 걸 할 수 있나요?\n","사용자: 상사가 너무 무섭게 생겨서 친해지는 게 너무 두려워.\n","챗봇: 상사가 옆을 지날 때마다 두려우시군요.\n","사용자: 종료\n","대화를 종료합니다.\n"]}]}]}